# ðŸš€ RIVION: Complete Implementation Report
## Real-Time Multimodal Emotion-Aware Conversational Agent

**Project**: RIVION (RoboCompanion alternative: Video-Call Based Mental Wellness Chatbot)  
**Status**: Comprehensive Technical & Implementation Plan  
**Date**: December 5, 2025  
**MCA Focus**: Full-Stack ML + Computer Vision + Audio + NLP + Production Deployment  

---

# TABLE OF CONTENTS

1. [Executive Overview](#executive-overview)
2. [Detailed Requirements Analysis](#detailed-requirements)
3. [Technology Stack (Complete)](#technology-stack)
4. [File Structure & Architecture](#file-structure)
5. [Database Design](#database-design)
6. [API Endpoints Specification](#api-endpoints)
7. [Phase-by-Phase Implementation](#implementation-phases)
8. [Development Environment Setup](#environment-setup)
9. [Deployment & DevOps](#deployment)
10. [Testing Strategy](#testing)
11. [Best Practices & Standards](#best-practices)
12. [Timeline & Resource Allocation](#timeline)
13. [Troubleshooting Guide](#troubleshooting)
14. [Appendix: Code Templates](#appendix)

---

# 1. EXECUTIVE OVERVIEW

## Project Vision
RIVION is a web-based mental wellness platform that detects user emotions in real-time through:
- **Visual input** (webcam): Face expressions, micro-expressions, arousal level
- **Audio input** (microphone): Tone, stress indicators, speech patterns
- **Text input** (chat): Sentiment, emotion keywords, explicit statements
- **Fusion engine**: Combines all 3 signals into reliable emotion score
- **Adaptive response**: LLM generates emotion-aware, supportive responses
- **Tracking**: Multi-session stress/burnout prediction

## Key Differentiators
âœ… Real-time video interface (not batch processing)  
âœ… Multimodal (3 signals, not 1-2)  
âœ… Stress scoring (0-100, not just labels)  
âœ… Burnout prediction (multi-session tracking)  
âœ… Adaptive conversation (emotion-aware prompts)  
âœ… Privacy-first (on-device face processing)  

---

# 2. DETAILED REQUIREMENTS ANALYSIS

## 2.1 Functional Requirements (What System Must Do)

### Core Features

#### A. Video Chat Interface
- **Requirement**: Real-time bidirectional video/audio streaming
- **Details**:
  - Video display: User's own webcam feed + optional AI avatar
  - Resolution: 720p minimum (1080p preferred)
  - FPS: 25-30 FPS minimum for smooth interaction
  - Latency: <300ms end-to-end (user sees/hears response quickly)
  - Audio: Mono or stereo, 16kHz sampling rate
  - Browser compatibility: Chrome, Firefox, Safari, Edge

#### B. Face Emotion Detection
- **Requirement**: Real-time facial expression classification
- **Details**:
  - 7-emotion classification: Happy, Sad, Angry, Surprised, Fearful, Disgusted, Neutral
  - Confidence score: 0-1 (min 0.6 confidence to count)
  - Processing: <100ms per frame (30 FPS = 33ms frame, need <100ms processing)
  - Multiple faces: If >1 face in frame, detect primary face (closest/largest)
  - Robustness: Handles lighting variations, head poses, glasses, masks
  - Arousal detection: Pupil dilation, eye opening, jaw tension
  - Action units: Track subtle micro-expressions

#### C. Voice Emotion Detection
- **Requirement**: Audio stream emotion classification + stress indicators
- **Details**:
  - Audio segments: 2-5 second chunks
  - Features extracted: MFCC (40 coefficients), pitch, energy, zero-crossing rate
  - Emotion classes: 7-class (same as face)
  - Stress indicators: Elevated pitch, irregular breathing, fast speech rate
  - Processing: <500ms per segment
  - Noise robustness: Filter background noise (utility noise, traffic, etc.)

#### D. Text Emotion Detection
- **Requirement**: Chat message emotion classification + keyword extraction
- **Details**:
  - Input: User text messages
  - Output: Emotion label + confidence + sentiment score (-1 to +1)
  - Keyword extraction: Risk indicators ("exhausted", "give up", "hopeless", "alone")
  - Sarcasm detection: "Oh great, another meeting" = negative (not positive)
  - Entity recognition: Extract what user is stressed about (project, relationship, health)
  - Response time: <50ms per message

#### E. Multimodal Fusion Engine
- **Requirement**: Combine face + voice + text into single emotion signal
- **Details**:
  - Input: 3 emotion predictions with confidence scores
  - Method: Attention-based weighted voting
  - Output: Final emotion label + stress score (0-100) + confidence
  - Hidden stress detection: Flag contradictions (smile + flat voice + negative text)
  - Temporal smoothing: Apply 10-frame moving average (eliminates flicker)

#### F. Adaptive Conversation Engine
- **Requirement**: Generate emotion-aware responses via LLM
- **Details**:
  - System prompt: Dynamically modified based on detected emotion
  - If stressed: Slower, softer, more supportive tone
  - If calm: More energetic, motivational tone
  - Safety: Detect crisis language â†’ provide resources immediately
  - Context: Include emotion data in LLM prompt
  - Response time: <2 seconds (OpenAI API)

#### G. Stress Scoring & Burnout Prediction
- **Requirement**: Track stress over time + predict burnout risk
- **Details**:
  - Stress score: 0-100 (composite of arousal, vocal stress, text negativity)
  - Session tracking: Store score + emotion + keywords per session
  - Trend analysis: Compare current session to previous 5 sessions
  - Burnout risk: Low (<40), Medium (40-70), High (70-100)
  - Multi-session alert: If stress trend increasing â†’ recommend professional help

#### H. Analytics Dashboard
- **Requirement**: Visualize emotion data + trends
- **Details**:
  - Real-time stress gauge (0-100 dial)
  - Session timeline: Mood variation during conversation
  - Historical trends: Stress level over days/weeks
  - Emotion distribution: Pie chart of emotions encountered
  - Intervention effectiveness: Did suggestions help? (user feedback)

---

## 2.2 Non-Functional Requirements (How System Must Work)

### Performance Requirements
| Metric | Target | Justification |
|--------|--------|---------------|
| **Face detection latency** | <100ms | 30 FPS video = 33ms/frame, need headroom for processing |
| **Voice inference** | <500ms per 5-sec segment | Real-time doesn't mean instant for audio |
| **Text emotion** | <50ms | Instant feedback on chat messages |
| **LLM response** | <2 seconds | User expects near-instant responses |
| **Overall end-to-end** | <1 second | For smooth conversational feel |
| **Video FPS** | 25-30 FPS | Smooth video, not choppy |
| **Concurrent users** | 100+ | FastAPI async can handle easily |

### Security Requirements
| Aspect | Requirement | Implementation |
|--------|-------------|-----------------|
| **Video data** | Never stored on server | Process on-device only (client-side) |
| **Audio clips** | Delete after 5 seconds | Only extract features, discard waveform |
| **Chat messages** | Encrypted in transit & at rest | HTTPS + AES-256 encryption |
| **User data** | Deletable by user anytime | GDPR compliance, right to be forgotten |
| **API keys** | Secured, never exposed | Environment variables, .env files |
| **Authentication** | Prevent unauthorized access | JWT tokens, refresh tokens |

### Privacy Requirements
| Aspect | Requirement | Implementation |
|--------|-------------|-----------------|
| **Consent** | User explicitly opts in | Checkbox on first login |
| **Transparency** | Explain what's collected | Privacy policy + in-app tooltips |
| **Data minimization** | Collect only what's needed | Emotion labels only, not raw media |
| **Data retention** | Automatic deletion policy | Delete sessions >90 days old (configurable) |
| **No profiling** | Emotion data not used to manipulate | No A/B testing on suppressed emotion |

### Scalability Requirements
| Component | Target Capacity | Scaling Strategy |
|-----------|-----------------|------------------|
| **Concurrent users** | 100+ simultaneous WebRTC sessions | Horizontal scaling with load balancer |
| **Database** | 1M+ session records | PostgreSQL replication + read replicas |
| **File storage** | 1TB+ emotion logs | Cloud storage (S3/GCS) with archival |
| **API throughput** | 10K requests/second | FastAPI async + Kubernetes autoscaling |

---

# 3. TECHNOLOGY STACK (Complete)

## 3.1 Frontend Stack

### Core Framework
```
React 18.2+
â”œâ”€ TypeScript (type safety)
â”œâ”€ Vite (fast build tool, replaces CRA)
â””â”€ Node 18 LTS
```

### Real-Time Communication
```
WebRTC (getUserMedia API)
â”œâ”€ Video capture: navigator.mediaDevices.getUserMedia({video, audio})
â”œâ”€ Peer connection: RTCPeerConnection (optional for P2P, else WebSocket)
â””â”€ Audio processing: Web Audio API for feature extraction

Socket.io or native WebSocket
â”œâ”€ Bidirectional communication
â”œâ”€ Real-time event streaming
â””â”€ Fallback to HTTP long-polling
```

### UI Libraries
```
TailwindCSS 3.x
â”œâ”€ Utility-first CSS framework
â”œâ”€ Responsive design out-of-box
â””â”€ Dark mode support

shadcn/ui
â”œâ”€ Accessible component library built on Radix UI
â”œâ”€ Pre-built: Button, Input, Card, Dialog, Slider
â””â”€ Customizable with Tailwind

Recharts or Chart.js
â”œâ”€ Emotion timeline charts
â”œâ”€ Real-time data visualization
â””â”€ Dashboard analytics
```

### State Management
```
Zustand or Redux Toolkit
â”œâ”€ WebRTC connection state
â”œâ”€ Current emotion/stress data
â”œâ”€ User session info
â”œâ”€ Message history
â””â”€ UI state (modal open, sidebar visible)
```

### Video/Audio Utilities
```
simple-peer (WebRTC abstraction)
â”œâ”€ Simplifies WebRTC setup
â”œâ”€ Handle SDP negotiation
â””â”€ Connection state management

MediaDevices API (native)
â”œâ”€ getUserMedia for video/audio
â”œâ”€ Constraints: resolution, framerate
â””â”€ Permissions handling
```

### Development Tools
```
Vite (build tool)
â”œâ”€ Hot Module Replacement (HMR) for instant feedback
â”œâ”€ Faster builds than Webpack
â””â”€ Optimized production bundle

ESLint + Prettier
â”œâ”€ Code linting + formatting
â”œâ”€ Enforce code style
â””â”€ Pre-commit hooks (husky)

Vitest + React Testing Library
â”œâ”€ Unit tests
â”œâ”€ Component tests
â””â”€ Integration tests
```

---

## 3.2 Backend Stack

### Web Framework
```
FastAPI 0.95+
â”œâ”€ Async Python (asyncio)
â”œâ”€ Built-in OpenAPI docs (/docs)
â”œâ”€ Type hints with Pydantic
â”œâ”€ 10K+ RPS capability
â””â”€ CORS, WebSocket support

Uvicorn
â”œâ”€ ASGI server (Async Server Gateway Interface)
â”œâ”€ Single-threaded, high concurrency
â”œâ”€ Production-grade
```

### Emotion Detection Services

#### A. Face Emotion
```
MediaPipe 0.10+
â”œâ”€ Face mesh detection: 468 landmarks
â”œâ”€ Real-time 30 FPS on consumer GPU
â”œâ”€ Handles: Rotation, occlusion, lighting
â”œâ”€ No model training needed
â””â”€ Lightweight (80MB)

DeepFace 0.0.71+
â”œâ”€ Ensemble of 4 pre-trained CNNs
â”œâ”€ 7-emotion classification
â”œâ”€ 95%+ accuracy on FER2013
â”œâ”€ Pre-trained models (no training needed)
â””â”€ Models: VGGFace, Facenet, OpenFace, DeepID

OpenCV 4.8+
â”œâ”€ Image processing
â”œâ”€ Frame capture from video stream
â”œâ”€ Face rectangle drawing
â””â”€ Utility functions
```

#### B. Voice Emotion
```
Librosa 0.10+
â”œâ”€ Audio feature extraction
â”œâ”€ MFCC (40 coefficients)
â”œâ”€ Pitch, energy, ZCR
â””â”€ Noise reduction

SoundFile
â”œâ”€ Read/write audio files
â”œâ”€ WAV, FLAC support
â””â”€ 16-bit mono recommended

NumPy + SciPy
â”œâ”€ Audio signal processing
â”œâ”€ FFT for frequency analysis
â””â”€ Statistical features

PyTorch 2.0+
â”œâ”€ Pre-trained audio models
â”œâ”€ CNN-LSTM architecture
â”œâ”€ GPU acceleration
â””â”€ Model inference

HuBERT / WavLM (optional)
â”œâ”€ Pre-trained audio embeddings
â”œâ”€ Transfer learning for voice emotion
â””â”€ Fine-tuning on IEMOCAP dataset
```

#### C. Text Emotion
```
HuggingFace Transformers 4.35+
â”œâ”€ BERT, RoBERTa, DistilBERT
â”œâ”€ Pre-trained on 3.3B words
â”œâ”€ 768-dimensional embeddings
â””â”€ Pipeline API for easy inference

VADER Sentiment
â”œâ”€ Rule-based sentiment analysis
â”œâ”€ Fast (no neural network)
â”œâ”€ Good for informal text
â””â”€ Handles emoticons, slang

spaCy 3.7+
â”œâ”€ Named entity recognition (NER)
â”œâ”€ Extract: Person, Organization, Event, Product
â”œâ”€ Dependency parsing
â””â”€ Custom trained models (optional)

NLTK 3.8+
â”œâ”€ Tokenization
â”œâ”€ Lemmatization
â”œâ”€ Stopword removal
â””â”€ Corpus data
```

### Fusion & LLM Integration

```
NumPy + Pandas
â”œâ”€ Attention mechanism implementation
â”œâ”€ Weighted voting
â”œâ”€ Data manipulation
â””â”€ Statistical analysis

OpenAI Python SDK
â”œâ”€ GPT-4, GPT-3.5-turbo API calls
â”œâ”€ Streaming responses
â”œâ”€ Token counting
â””â”€ Error handling

Pydantic v2
â”œâ”€ Data validation
â”œâ”€ Type hints for API requests/responses
â”œâ”€ JSON schema generation
â””â”€ Settings management (BaseSettings)
```

### Database
```
PostgreSQL 15+
â”œâ”€ Relational data (users, sessions, emotions)
â”œâ”€ ACID compliance
â”œâ”€ Full-text search
â”œâ”€ JSONB for flexible schema
â””â”€ Time-series data (emotion logs)

SQLAlchemy 2.0+
â”œâ”€ ORM (Object Relational Mapping)
â”œâ”€ Database-agnostic queries
â”œâ”€ Connection pooling (asyncpg)
â””â”€ Migrations (Alembic)

Alembic
â”œâ”€ Database schema versioning
â”œâ”€ Automatic migration scripts
â””â”€ Rollback capability

Redis (optional)
â”œâ”€ Session cache
â”œâ”€ Real-time data (current mood)
â”œâ”€ Rate limiting
â””â”€ Job queue (Celery)
```

### Supporting Services

```
Celery + Redis
â”œâ”€ Async task queue
â”œâ”€ Offload heavy computation
â”œâ”€ Email notifications
â””â”€ Periodic cleanup jobs

APScheduler
â”œâ”€ Scheduled jobs
â”œâ”€ Cleanup old sessions
â”œâ”€ Send daily reports
â””â”€ Burnout risk re-calculation

python-dotenv
â”œâ”€ Environment variables
â”œâ”€ API keys (OpenAI, etc.)
â”œâ”€ Database URL
â””â”€ Debug mode toggle
```

### Development Tools
```
Pytest
â”œâ”€ Unit tests
â”œâ”€ Integration tests
â”œâ”€ Fixtures + mocking
â””â”€ Code coverage reports

Black + isort
â”œâ”€ Python code formatting
â”œâ”€ Import organization
â””â”€ Enforce PEP 8 style

Pylint + mypy
â”œâ”€ Static code analysis
â”œâ”€ Type checking
â”œâ”€ Detect bugs early
â””â”€ Pre-commit hooks
```

---

## 3.3 DevOps & Deployment Stack

### Containerization
```
Docker
â”œâ”€ Dockerfile: Backend + ML services
â”œâ”€ docker-compose.yml: Local development
â”œâ”€ Multi-stage builds (reduce image size)
â””â”€ .dockerignore (exclude unnecessary files)

Docker Compose
â”œâ”€ Run PostgreSQL + FastAPI + Redis locally
â”œâ”€ Environment variable injection
â”œâ”€ Network bridging
â””â”€ Volume mounting for development
```

### Cloud Deployment Options

#### Option A: AWS (Recommended)
```
EC2 Instances
â”œâ”€ t3.large (backend) or t3.xlarge (GPU inference)
â”œâ”€ Auto Scaling Group for scaling
â”œâ”€ Security groups + VPC
â””â”€ Estimated: $50-200/month

RDS (PostgreSQL)
â”œâ”€ Managed database
â”œâ”€ Automated backups
â”œâ”€ Read replicas for scaling
â””â”€ Estimated: $20-50/month

S3
â”œâ”€ Store session logs, dashboards
â”œâ”€ Media files (optional)
â””â”€ Estimated: <$5/month

ALB (Application Load Balancer)
â”œâ”€ Route traffic to EC2 instances
â”œâ”€ SSL/TLS termination
â”œâ”€ Sticky sessions for WebSocket
â””â”€ Estimated: $15-20/month

CloudFront
â”œâ”€ CDN for static assets
â”œâ”€ Cache React bundle, charts
â””â”€ Estimated: <$5/month

TOTAL AWS COST: ~$100-300/month
```

#### Option B: GCP (Alternative)
```
Cloud Run (serverless)
â”œâ”€ Auto-scales to zero
â”œâ”€ Pay per request
â”œâ”€ FastAPI compatible
â””â”€ Estimated: $10-30/month

Cloud SQL (PostgreSQL)
â”œâ”€ Similar to AWS RDS
â”œâ”€ Estimated: $15-40/month

Cloud Storage + CDN
â”œâ”€ Similar to S3 + CloudFront
â””â”€ Estimated: <$5/month

TOTAL GCP COST: ~$30-75/month (cheaper than AWS)
```

#### Option C: Heroku (Simplest for MCA)
```
Heroku Dyno
â”œâ”€ Standard 1X or 2X
â”œâ”€ Auto-restart on crash
â”œâ”€ Easy GitHub integration
â””â”€ Estimated: $7-50/month

Heroku Postgres
â”œâ”€ Managed database
â”œâ”€ Estimated: $9-50/month

TOTAL HEROKU COST: ~$20-100/month (easiest, not cheapest)
```

### CI/CD Pipeline
```
GitHub Actions (free for public repos)
â”œâ”€ Trigger: On push to main/dev
â”œâ”€ Test: Run pytest suite
â”œâ”€ Build: Docker image
â”œâ”€ Deploy: To AWS/GCP/Heroku
â””â”€ Workflows: .github/workflows/*.yml

GitLab CI (if using GitLab)
â”œâ”€ Similar pipeline
â”œâ”€ More storage for artifacts
â””â”€ Self-hosted runners available
```

### Monitoring & Logging
```
Sentry
â”œâ”€ Error tracking
â”œâ”€ Real-time alerts
â”œâ”€ Source map support
â””â”€ Free tier: 5,000 errors/month

Datadog (optional)
â”œâ”€ APM (Application Performance Monitoring)
â”œâ”€ Real-time metrics
â”œâ”€ Custom dashboards
â””â”€ Estimated: $50+/month

CloudWatch (AWS) or Stackdriver (GCP)
â”œâ”€ Built-in logging
â”œâ”€ Metrics dashboards
â””â”€ Included with cloud provider

Prometheus + Grafana (self-hosted)
â”œâ”€ Open source alternative
â”œâ”€ Real-time metrics
â””â”€ Cost: Server hosting (~$20/month)
```

---

## 3.4 Analytics & Dashboard Stack

### Dashboard Tools
```
Streamlit (Quickest for MVP)
â”œâ”€ Python-based web app
â”œâ”€ No JavaScript needed
â”œâ”€ Charts built-in
â”œâ”€ Rerun on code change
â”œâ”€ Deployment: streamlit.io (free)

React Dashboard (More control)
â”œâ”€ Custom React components
â”œâ”€ Same frontend as chatbot
â”œâ”€ Recharts for visualizations
â”œâ”€ More effort but flexible
```

### Data Visualization
```
Recharts
â”œâ”€ React library
â”œâ”€ Line charts (emotion over time)
â”œâ”€ Pie charts (emotion distribution)
â”œâ”€ Responsive design
â””â”€ TypeScript support

Plotly (Python)
â”œâ”€ Interactive charts
â”œâ”€ 3D visualizations
â”œâ”€ Export to HTML
â””â”€ Works with Streamlit
```

---

# 4. FILE STRUCTURE & ARCHITECTURE

## 4.1 Project Root Structure

```
RIVION/
â”œâ”€â”€ frontend/                          # React application
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/               # UI components
â”‚   â”‚   â”‚   â”œâ”€â”€ VideoChat/            # Main video interface
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VideoChat.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ VideoChat.module.css
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ EmotionDisplay.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ChatBox.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ AvatarDisplay.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ StressGauge.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ EmotionTimeline.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ HistoricalTrends.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EmotionDistribution.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Common/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Header.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Modal.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ Button.tsx
â”‚   â”‚   â”‚   â””â”€â”€ Auth/
â”‚   â”‚   â”‚       â”œâ”€â”€ Login.tsx
â”‚   â”‚   â”‚       â”œâ”€â”€ Register.tsx
â”‚   â”‚   â”‚       â””â”€â”€ ProtectedRoute.tsx
â”‚   â”‚   â”œâ”€â”€ pages/                    # Page components
â”‚   â”‚   â”‚   â”œâ”€â”€ HomePage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatPage.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ DashboardPage.tsx
â”‚   â”‚   â”‚   â””â”€â”€ SettingsPage.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/                    # Custom React hooks
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebRTC.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useEmotion.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useLocalStorage.ts
â”‚   â”‚   â”‚   â””â”€â”€ useAuth.ts
â”‚   â”‚   â”œâ”€â”€ services/                 # API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts               # Axios/fetch wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ emotionService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ chatService.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ authService.ts
â”‚   â”‚   â”‚   â””â”€â”€ dashboardService.ts
â”‚   â”‚   â”œâ”€â”€ store/                    # State management (Zustand)
â”‚   â”‚   â”‚   â”œâ”€â”€ emotionStore.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ chatStore.ts
â”‚   â”‚   â”‚   â””â”€â”€ authStore.ts
â”‚   â”‚   â”œâ”€â”€ types/                    # TypeScript types
â”‚   â”‚   â”‚   â”œâ”€â”€ emotion.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ user.ts
â”‚   â”‚   â”‚   â””â”€â”€ chat.ts
â”‚   â”‚   â”œâ”€â”€ utils/                    # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ formatters.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ validators.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ constants.ts
â”‚   â”‚   â”‚   â””â”€â”€ logger.ts
â”‚   â”‚   â”œâ”€â”€ styles/                   # Global styles
â”‚   â”‚   â”‚   â”œâ”€â”€ globals.css
â”‚   â”‚   â”‚   â”œâ”€â”€ variables.css
â”‚   â”‚   â”‚   â””â”€â”€ animations.css
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â”œâ”€â”€ App.module.css
â”‚   â”‚   â”œâ”€â”€ main.tsx
â”‚   â”‚   â””â”€â”€ index.css
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tsconfig.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â”œâ”€â”€ .env.example
â”‚   â””â”€â”€ .gitignore
â”‚
â”œâ”€â”€ backend/                           # FastAPI application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                  # Entry point
â”‚   â”‚   â”œâ”€â”€ config.py                # Settings/config
â”‚   â”‚   â”œâ”€â”€ dependencies.py          # Dependency injection
â”‚   â”‚   â”œâ”€â”€ middleware.py            # CORS, logging, etc.
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ routers/                 # API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py              # /api/auth/* endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py              # /api/chat/* endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ emotion.py           # /api/emotion/* endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard.py         # /api/dashboard/* endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py            # /api/health endpoint
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/                  # Database models (SQLAlchemy ORM)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py              # User model
â”‚   â”‚   â”‚   â”œâ”€â”€ session.py           # Chat session model
â”‚   â”‚   â”‚   â”œâ”€â”€ emotion_log.py       # Emotion record model
â”‚   â”‚   â”‚   â”œâ”€â”€ message.py           # Chat message model
â”‚   â”‚   â”‚   â””â”€â”€ base.py              # Base model class
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ schemas/                 # Pydantic schemas (request/response validation)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”‚   â”œâ”€â”€ emotion.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â””â”€â”€ dashboard.py
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ face_emotion_service.py      # MediaPipe + DeepFace
â”‚   â”‚   â”‚   â”œâ”€â”€ voice_emotion_service.py     # Librosa + PyTorch
â”‚   â”‚   â”‚   â”œâ”€â”€ text_emotion_service.py      # BERT + spaCy
â”‚   â”‚   â”‚   â”œâ”€â”€ fusion_service.py            # Multimodal fusion
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py               # OpenAI API wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py              # JWT, password hashing
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_service.py              # Chat logic
â”‚   â”‚   â”‚   â”œâ”€â”€ emotion_service.py           # Emotion tracking
â”‚   â”‚   â”‚   â””â”€â”€ dashboard_service.py         # Analytics
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging setup
â”‚   â”‚   â”‚   â”œâ”€â”€ validators.py        # Input validation
â”‚   â”‚   â”‚   â”œâ”€â”€ decorators.py        # Custom decorators
â”‚   â”‚   â”‚   â”œâ”€â”€ helpers.py           # Helper functions
â”‚   â”‚   â”‚   â””â”€â”€ constants.py         # Constants
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ db/                      # Database
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py          # Connection setup
â”‚   â”‚   â”‚   â”œâ”€â”€ session.py           # Session management
â”‚   â”‚   â”‚   â””â”€â”€ init_db.py           # Initialize DB
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ ml_models/               # Pre-trained models (cache)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ face_models/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ deepface_models.pth (if custom trained)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mediapipe_face_detection.tflite
â”‚   â”‚   â”‚   â”œâ”€â”€ voice_models/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ speech_emotion_model.pt (CNN-LSTM)
â”‚   â”‚   â”‚   â””â”€â”€ text_models/
â”‚   â”‚   â”‚       â””â”€â”€ bert_emotion_model/ (HF model cache)
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ websocket/               # WebSocket handlers
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ connection_manager.py
â”‚   â”‚       â”œâ”€â”€ event_handlers.py
â”‚   â”‚       â””â”€â”€ middleware.py
â”‚   â”‚
â”‚   â”œâ”€â”€ migrations/                  # Alembic database migrations
â”‚   â”‚   â”œâ”€â”€ versions/
â”‚   â”‚   â”œâ”€â”€ env.py
â”‚   â”‚   â”œâ”€â”€ script.py.mako
â”‚   â”‚   â””â”€â”€ alembic.ini
â”‚   â”‚
â”‚   â”œâ”€â”€ tests/                       # Test suite
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ conftest.py              # Pytest fixtures
â”‚   â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_emotion_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_fusion_service.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_auth_service.py
â”‚   â”‚   â”‚   â””â”€â”€ test_llm_service.py
â”‚   â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_websocket.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_auth_flow.py
â”‚   â”‚   â”‚   â””â”€â”€ test_chat_flow.py
â”‚   â”‚   â””â”€â”€ e2e/
â”‚   â”‚       â””â”€â”€ test_full_workflow.py
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt              # Python dependencies
â”‚   â”œâ”€â”€ requirements-dev.txt          # Dev dependencies
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â”œâ”€â”€ .env.example
â”‚   â”œâ”€â”€ .gitignore
â”‚   â””â”€â”€ pyproject.toml               # Project metadata
â”‚
â”œâ”€â”€ dashboard/                         # Streamlit app (optional)
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ home.py
â”‚   â”‚   â”œâ”€â”€ emotion_analysis.py
â”‚   â”‚   â”œâ”€â”€ stress_tracking.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ charts.py
â”‚   â”‚   â””â”€â”€ tables.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ .streamlit/
â”‚   â”‚   â””â”€â”€ config.toml
â”‚   â””â”€â”€ .gitignore
â”‚
â”œâ”€â”€ docker-compose.yml               # Local development stack
â”œâ”€â”€ docker-compose.prod.yml          # Production stack
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ test.yml                 # Run tests on PR
â”‚       â”œâ”€â”€ build.yml                # Build Docker image
â”‚       â””â”€â”€ deploy.yml               # Deploy to cloud
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                         # Project documentation
â”œâ”€â”€ CONTRIBUTING.md                   # Contribution guidelines
â”œâ”€â”€ LICENSE
â””â”€â”€ ARCHITECTURE.md                   # Detailed architecture docs

```

---

## 4.2 Backend Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FRONTEND (React)                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Video Stream â”‚  â”‚ Audio Stream â”‚  â”‚ Text Input   â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                 â”‚                 â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (WebSocket/REST)
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASTAPI BACKEND                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                    API ROUTER LAYER                              â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  /api/auth/*      /api/chat/*     /api/emotion/*  /api/dash/*   â”‚ â”‚
â”‚  â”‚  (JWT tokens)     (Messages)      (Stream data)   (Analytics)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â”‚
â”‚            â”‚               â”‚                â”‚                â”‚     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”‚
â”‚  â”‚              MIDDLEWARE & DEPENDENCIES                         â”‚ â”‚
â”‚  â”‚  â”œâ”€ CORS handler                                              â”‚ â”‚
â”‚  â”‚  â”œâ”€ JWT authentication                                        â”‚ â”‚
â”‚  â”‚  â”œâ”€ Rate limiting                                             â”‚ â”‚
â”‚  â”‚  â”œâ”€ Request/response logging                                  â”‚ â”‚
â”‚  â”‚  â””â”€ Error handling                                            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â”‚
â”‚            â”‚                                                 â”‚     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”‚
â”‚  â”‚                   SERVICE LAYER                              â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                                                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚ Face Emotion    â”‚  â”‚ Voice Emotion    â”‚  â”‚ Text Emotion â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ Service         â”‚  â”‚ Service          â”‚  â”‚ Service      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                 â”‚  â”‚                  â”‚  â”‚              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ MediaPipe     â”‚  â”‚ â€¢ Librosa MFCC   â”‚  â”‚ â€¢ BERT       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ DeepFace      â”‚  â”‚ â€¢ PyTorch LSTM   â”‚  â”‚ â€¢ spaCy NER  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ â€¢ OpenCV        â”‚  â”‚ â€¢ WavLM/HuBERT   â”‚  â”‚ â€¢ VADER      â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚           â”‚                    â”‚                   â”‚         â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚         FUSION ENGINE                                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Attention-based weighted voting                      â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Hidden stress detection                              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Confidence scoring                                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Temporal smoothing (10-frame MA)                     â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚           â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚         LLM SERVICE                                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ OpenAI API wrapper                                 â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Dynamic system prompt (emotion-based)              â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Safety checks (crisis detection)                   â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Response streaming                                 â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚           â”‚                                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚    DATABASE & CACHE SERVICES                          â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ PostgreSQL (persistent data)                       â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ Redis (session cache, rate limit)                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â€¢ SQLAlchemy ORM                                     â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â”‚ (REST API, SQL queries, Redis commands)
          â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        EXTERNAL SERVICES & DATA             â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚  â€¢ PostgreSQL (primary database)             â”‚
    â”‚  â€¢ Redis (cache layer)                       â”‚
    â”‚  â€¢ OpenAI API (LLM responses)                â”‚
    â”‚  â€¢ Sentry (error tracking)                   â”‚
    â”‚  â€¢ AWS S3 (session backups)                  â”‚
    â”‚  â€¢ Mailgun (email notifications)             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 5. DATABASE DESIGN

## 5.1 Entity Relationship Diagram (ERD)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          USER                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK, UUID)                   â”‚
â”‚ email (UNIQUE)                  â”‚
â”‚ username                        â”‚
â”‚ password_hash                   â”‚
â”‚ created_at                      â”‚
â”‚ updated_at                      â”‚
â”‚ deleted_at (soft delete)        â”‚
â”‚ privacy_consent (BOOLEAN)       â”‚
â”‚ data_retention_days (INT)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ (1:N)
                 â”‚ owns
                 â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      SESSION                 â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ id (PK, UUID)                â”‚
         â”‚ user_id (FK)                 â”‚
         â”‚ session_start (TIMESTAMP)    â”‚
         â”‚ session_end (TIMESTAMP)      â”‚
         â”‚ total_stress_score (FLOAT)   â”‚
         â”‚ dominant_emotion (VARCHAR)   â”‚
         â”‚ burnout_risk_level (ENUM)    â”‚
         â”‚ notes (TEXT)                 â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚          â”‚
            (1:N)â”‚ contains â”‚ (1:N)
                 â”‚          â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    MESSAGE     â”‚  â”‚   EMOTION_LOG      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ id (PK)        â”‚  â”‚ id (PK)            â”‚
    â”‚ session_id(FK) â”‚  â”‚ session_id (FK)    â”‚
    â”‚ sender (ENUM)  â”‚  â”‚ timestamp          â”‚
    â”‚ â”‚(USER/AI)     â”‚  â”‚ face_emotion       â”‚
    â”‚ content (TEXT) â”‚  â”‚ face_confidence    â”‚
    â”‚ emotion_label  â”‚  â”‚ voice_emotion      â”‚
    â”‚ created_at     â”‚  â”‚ voice_confidence   â”‚
    â”‚ tokens_used    â”‚  â”‚ text_emotion       â”‚
    â”‚ response_time  â”‚  â”‚ text_confidence    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ final_emotion      â”‚
                        â”‚ stress_score (0-100)
                        â”‚ hidden_stress      â”‚
                        â”‚ face_features(JSONB)
                        â”‚ voice_features(JSONB)
                        â”‚ text_keywords(JSONB)
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ADDITIONAL TABLES:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   EMOTION_STATISTICS   â”‚  (aggregated for performance)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                â”‚
â”‚ user_id (FK)           â”‚
â”‚ date (DATE)            â”‚
â”‚ avg_stress_score       â”‚
â”‚ emotion_counts (JSONB) â”‚ {"happy": 5, "sad": 2, ...}
â”‚ burnout_risk           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FEEDBACK             â”‚  (user feedback on suggestions)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                â”‚
â”‚ session_id (FK)        â”‚
â”‚ suggestion             â”‚ (VARCHAR, e.g., "breathing_exercise")
â”‚ was_helpful (BOOLEAN)  â”‚
â”‚ rating (INT, 1-5)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AUDIT_LOG            â”‚  (track all API calls)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id (PK)                â”‚
â”‚ user_id (FK)           â”‚
â”‚ action (VARCHAR)       â”‚
â”‚ resource (VARCHAR)     â”‚
â”‚ timestamp              â”‚
â”‚ ip_address             â”‚
â”‚ user_agent             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 5.2 Database Schema (SQL)

```sql
-- Users table
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    email VARCHAR(255) UNIQUE NOT NULL,
    username VARCHAR(100) NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    deleted_at TIMESTAMP,
    privacy_consent BOOLEAN DEFAULT FALSE,
    data_retention_days INT DEFAULT 90,
    is_active BOOLEAN DEFAULT TRUE
);

-- Sessions table
CREATE TABLE sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    session_start TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    session_end TIMESTAMP,
    total_stress_score FLOAT,
    dominant_emotion VARCHAR(50),
    burnout_risk_level VARCHAR(20), -- LOW, MEDIUM, HIGH
    notes TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Messages table
CREATE TABLE messages (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES sessions(id) ON DELETE CASCADE,
    sender VARCHAR(10) NOT NULL, -- USER or AI
    content TEXT NOT NULL,
    emotion_label VARCHAR(50),
    tokens_used INT,
    response_time_ms INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Emotion logs table (high-frequency data)
CREATE TABLE emotion_logs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES sessions(id) ON DELETE CASCADE,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    
    -- Face emotion
    face_emotion VARCHAR(50),
    face_confidence FLOAT,
    face_arousal FLOAT, -- 0-1
    face_valence FLOAT, -- 0-1
    face_features JSONB, -- {landmarks, action_units, ...}
    
    -- Voice emotion
    voice_emotion VARCHAR(50),
    voice_confidence FLOAT,
    voice_stress FLOAT, -- 0-1
    voice_tone VARCHAR(50), -- calm, stressed, angry, etc.
    voice_features JSONB, -- {pitch, energy, mfcc, ...}
    
    -- Text emotion
    text_emotion VARCHAR(50),
    text_confidence FLOAT,
    text_sentiment FLOAT, -- -1 to 1
    text_keywords JSONB, -- ["exhausted", "overwhelmed"]
    text_risk_level VARCHAR(20), -- NORMAL, MILD, MODERATE, SEVERE
    
    -- Fusion results
    final_emotion VARCHAR(50),
    final_confidence FLOAT,
    stress_score INT, -- 0-100
    hidden_stress_detected BOOLEAN,
    
    INDEX idx_session_time (session_id, timestamp DESC)
);

-- Emotion statistics (aggregated daily)
CREATE TABLE emotion_statistics (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    date DATE NOT NULL,
    avg_stress_score FLOAT,
    max_stress_score INT,
    emotion_distribution JSONB, -- {"happy": 30, "sad": 20, ...}
    burnout_risk_level VARCHAR(20),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(user_id, date)
);

-- Feedback table
CREATE TABLE feedback (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    session_id UUID NOT NULL REFERENCES sessions(id) ON DELETE CASCADE,
    suggestion_type VARCHAR(100), -- breathing_exercise, task_breakdown, etc.
    was_helpful BOOLEAN,
    rating INT CHECK (rating >= 1 AND rating <= 5),
    user_comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for performance
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_sessions_user_date ON sessions(user_id, session_start DESC);
CREATE INDEX idx_emotion_logs_session ON emotion_logs(session_id);
CREATE INDEX idx_emotion_stats_user_date ON emotion_statistics(user_id, date DESC);

-- Enable full-text search on messages
CREATE INDEX idx_messages_content_fts ON messages USING GIN(to_tsvector('english', content));
```

---

# 6. API ENDPOINTS SPECIFICATION

## 6.1 Authentication Endpoints

```
POST /api/auth/register
â”œâ”€ Request: { email, username, password, privacy_consent }
â”œâ”€ Response: { user_id, token, refresh_token }
â”œâ”€ Status: 201 Created
â””â”€ Errors: 400 (validation), 409 (user exists)

POST /api/auth/login
â”œâ”€ Request: { email, password }
â”œâ”€ Response: { user_id, token, refresh_token, expires_in }
â”œâ”€ Status: 200 OK
â””â”€ Errors: 401 (invalid credentials), 404 (user not found)

POST /api/auth/logout
â”œâ”€ Request: { token }
â”œâ”€ Response: { message: "Logged out" }
â”œâ”€ Status: 200 OK
â””â”€ Auth: Required

POST /api/auth/refresh
â”œâ”€ Request: { refresh_token }
â”œâ”€ Response: { token, refresh_token }
â”œâ”€ Status: 200 OK
â””â”€ Errors: 401 (invalid token)

GET /api/auth/me
â”œâ”€ Response: { user_id, email, username, created_at }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Errors: 401 (not authenticated)

PUT /api/auth/profile
â”œâ”€ Request: { first_name, last_name, privacy_consent }
â”œâ”€ Response: { user_id, ...updated_fields }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Errors: 400 (validation)

DELETE /api/auth/account
â”œâ”€ Request: { password_confirmation }
â”œâ”€ Response: { message: "Account deleted" }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Notes: GDPR right to be forgotten (cascade delete all user data)
```

## 6.2 Chat Endpoints

```
POST /api/chat/session/start
â”œâ”€ Request: { topic: "optional" }
â”œâ”€ Response: { session_id, timestamp }
â”œâ”€ Status: 201 Created
â”œâ”€ Auth: Required
â””â”€ WebSocket: Opens WebSocket connection for real-time chat

WS /api/chat/stream
â”œâ”€ Connect: Opens bidirectional WebSocket
â”œâ”€ Listen events:
â”‚  â”œâ”€ video_frame: { frame_base64, timestamp }
â”‚  â”œâ”€ audio_chunk: { audio_base64, duration_ms }
â”‚  â””â”€ text_message: { content, timestamp }
â”œâ”€ Emit events:
â”‚  â”œâ”€ emotion_update: { emotion, stress_score, confidence }
â”‚  â”œâ”€ ai_response: { message, suggestion }
â”‚  â””â”€ error: { code, message }
â”œâ”€ Auth: JWT token in query params
â””â”€ Heartbeat: Every 30 seconds

POST /api/chat/message
â”œâ”€ Request: { session_id, content }
â”œâ”€ Response: { message_id, ai_response, emotion_detected }
â”œâ”€ Status: 201 Created
â”œâ”€ Auth: Required
â””â”€ Notes: Alternative to WebSocket (slower, for backup)

POST /api/chat/session/end
â”œâ”€ Request: { session_id }
â”œâ”€ Response: { session_summary, stress_trend, recommendations }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Notes: Close session, compute final stats

GET /api/chat/sessions
â”œâ”€ Query: { limit: 20, offset: 0, sort: "date" }
â”œâ”€ Response: { sessions: [...], total: 100 }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Pagination: offset-limit based

GET /api/chat/session/{session_id}
â”œâ”€ Response: { session_id, messages: [...], emotions: [...], stats: {...} }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Errors: 404 (session not found)
```

## 6.3 Emotion Analysis Endpoints

```
POST /api/emotion/analyze-face
â”œâ”€ Request: { frame_base64 }
â”œâ”€ Response: { emotion, confidence, arousal, landmarks: [...] }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Optional
â””â”€ Processing time: <100ms

POST /api/emotion/analyze-voice
â”œâ”€ Request: { audio_base64, duration_ms }
â”œâ”€ Response: { emotion, confidence, stress_level, tone }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Optional
â””â”€ Processing time: <500ms

POST /api/emotion/analyze-text
â”œâ”€ Request: { text }
â”œâ”€ Response: { emotion, confidence, sentiment, keywords: [...], risk_level }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Optional
â””â”€ Processing time: <50ms

POST /api/emotion/fuse
â”œâ”€ Request: { face_emotion, voice_emotion, text_emotion, confidences }
â”œâ”€ Response: { final_emotion, stress_score, hidden_stress_detected }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Optional
â””â”€ Algorithm: Attention-based weighted voting

GET /api/emotion/history/{session_id}
â”œâ”€ Response: { emotions: [...], timeline: {...}, average_stress }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Notes: Time-series data for graphs
```

## 6.4 Dashboard Endpoints

```
GET /api/dashboard/summary
â”œâ”€ Query: { date_range: "7d" | "30d" | "90d" }
â”œâ”€ Response: {
â”‚    current_stress: 45,
â”‚    burnout_risk: "low",
â”‚    avg_stress_trend: [...],
â”‚    emotion_distribution: {...},
â”‚    recommendations: [...]
â”‚  }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Performance: Cached, updated hourly

GET /api/dashboard/stress-trend
â”œâ”€ Query: { days: 30 }
â”œâ”€ Response: { 
â”‚    data: [
â”‚      { date: "2025-12-01", stress: 45, emotion: "calm" },
â”‚      { date: "2025-12-02", stress: 62, emotion: "stressed" }
â”‚    ]
â”‚  }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Aggregated per session

GET /api/dashboard/emotion-distribution
â”œâ”€ Query: { days: 7 }
â”œâ”€ Response: {
â”‚    happy: 10,
â”‚    sad: 5,
â”‚    angry: 3,
â”‚    neutral: 20,
â”‚    ...
â”‚  }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Percentage or count

GET /api/dashboard/burnout-risk
â”œâ”€ Response: {
â”‚    risk_level: "MEDIUM",
â”‚    score: 62,
â”‚    factors: ["increasing_stress", "declining_mood"],
â”‚    recommendations: ["seek_professional_help", "reduce_workload"]
â”‚  }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Algorithm: Multi-factor analysis

POST /api/dashboard/export
â”œâ”€ Query: { format: "csv" | "pdf", date_range: "90d" }
â”œâ”€ Response: Binary file (download)
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Privacy: User data only, anonymized
```

## 6.5 Settings & Preferences Endpoints

```
GET /api/settings/preferences
â”œâ”€ Response: { 
â”‚    theme: "dark",
â”‚    notification_enabled: true,
â”‚    data_retention_days: 90,
â”‚    privacy_level: "high"
â”‚  }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ User-specific settings

PUT /api/settings/preferences
â”œâ”€ Request: { theme, notification_enabled, data_retention_days }
â”œâ”€ Response: { updated_at, preferences }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â””â”€ Validates each field

DELETE /api/settings/data
â”œâ”€ Request: { confirm: true }
â”œâ”€ Response: { message: "All data deleted" }
â”œâ”€ Status: 200 OK
â”œâ”€ Auth: Required
â”œâ”€ GDPR: Right to be forgotten
â””â”€ Irreversible: Cannot undo
```

---

# 7. PHASE-BY-PHASE IMPLEMENTATION

## PHASE 1: MVP (Weeks 1-4) - Face + Text Only

### 7.1.1 Week 1: Setup & Foundation

**Backend Tasks:**
- [ ] Create FastAPI project structure
- [ ] Set up PostgreSQL locally (docker-compose)
- [ ] Implement user registration/login (JWT auth)
- [ ] Create database models (User, Session, Message, EmotionLog)
- [ ] Implement basic CORS + error handling middleware

**Frontend Tasks:**
- [ ] Create React + TypeScript project (Vite)
- [ ] Set up TailwindCSS + shadcn/ui
- [ ] Create login/register pages
- [ ] Set up Zustand store for auth state
- [ ] Implement basic routing (home, chat, settings)

**DevOps:**
- [ ] Initialize Docker Compose setup
- [ ] Configure .env files
- [ ] Set up GitHub repo + .gitignore
- [ ] Create basic CI/CD workflow (GitHub Actions)

**Deliverables:**
- Scaffolded project structure
- Users can register/login
- Auth token management working
- Docker environment ready

---

### 7.1.2 Week 2: Face Emotion Detection

**Backend Tasks:**
- [ ] Create `face_emotion_service.py` (MediaPipe + DeepFace)
  ```python
  import mediapipe as mp
  import cv2
  from deepface import DeepFace
  
  class FaceEmotionService:
      def __init__(self):
          self.mp_face = mp.solutions.face_detection
          self.face_detector = self.mp_face.FaceDetection()
      
      def detect_emotion(self, frame):
          # 1. Detect face in frame
          # 2. Extract face region
          # 3. Use DeepFace to classify emotion
          # 4. Extract landmarks from MediaPipe
          # 5. Calculate arousal (eye opening, jaw tension)
          # 6. Return {emotion, confidence, arousal, landmarks}
          pass
  ```
- [ ] Create `/api/emotion/analyze-face` endpoint
- [ ] Add endpoint tests

**Frontend Tasks:**
- [ ] Implement video stream component (getUserMedia API)
  ```javascript
  const videoRef = useRef<HTMLVideoElement>(null);
  
  useEffect(() => {
    navigator.mediaDevices.getUserMedia({
      video: { width: 640, height: 480 },
      audio: false
    })
    .then(stream => videoRef.current.srcObject = stream);
  }, []);
  ```
- [ ] Create EmotionDisplay component (shows detected emotion + confidence)
- [ ] Implement WebSocket connection (socket.io)
- [ ] Create chat UI (textarea + message list)

**Testing:**
- [ ] Unit tests for face emotion detection
- [ ] Integration test: upload frame â†’ get emotion
- [ ] API tests with Pytest

**Deliverables:**
- Face emotion detection working in real-time
- Video stream displaying in UI
- Emotion labels showing with confidence scores
- Tests passing

---

### 7.1.3 Week 3: Text Emotion & Chat Integration

**Backend Tasks:**
- [ ] Create `text_emotion_service.py` (BERT + spaCy)
  ```python
  from transformers import pipeline
  import spacy
  
  class TextEmotionService:
      def __init__(self):
          self.emotion_classifier = pipeline("text-classification", 
                                             model="j-hartmann/emotion-english-distilroberta-base")
          self.nlp = spacy.load("en_core_web_sm")
      
      def analyze_text(self, text):
          # 1. Classify emotion using BERT
          # 2. Extract entities using spaCy
          # 3. Detect risk keywords ("give up", "hopeless", etc.)
          # 4. Calculate sentiment
          # 5. Return {emotion, confidence, keywords, sentiment, risk_level}
          pass
  ```
- [ ] Create `/api/emotion/analyze-text` endpoint
- [ ] Create `llm_service.py` (OpenAI wrapper)
  ```python
  from openai import AsyncOpenAI
  
  class LLMService:
      def __init__(self, api_key):
          self.client = AsyncOpenAI(api_key=api_key)
      
      async def generate_response(self, user_message, emotion_data):
          # 1. Craft dynamic system prompt based on emotion
          # 2. Include emotion context in user message
          # 3. Call OpenAI API (streaming)
          # 4. Return response stream
          pass
  ```
- [ ] Create `/api/chat/message` endpoint (send message â†’ get response)
- [ ] Implement WebSocket event handlers (text messages)
- [ ] Create `chat_service.py` (message persistence, history)

**Frontend Tasks:**
- [ ] Implement ChatBox component (textarea + message list)
- [ ] Create Message component (display user/AI messages)
- [ ] Implement WebSocket text message sending/receiving
- [ ] Add emotion tags to messages (show detected emotion)
- [ ] Create conversation history sidebar

**Testing:**
- [ ] Test BERT emotion classification
- [ ] Test LLM integration with mock responses
- [ ] Test chat flow (send message â†’ get response)
- [ ] Test emotion persistence to database

**Deliverables:**
- Text-based emotion detection working
- Chat messages being sent/received
- AI responses generated with OpenAI API
- Chat history persistent in database

---

### 7.1.4 Week 4: Fusion + Basic Stress Scoring

**Backend Tasks:**
- [ ] Create `fusion_service.py` (combine face + text emotions)
  ```python
  import numpy as np
  
  class FusionService:
      def fuse_emotions(self, face_emotion, text_emotion, face_conf, text_conf):
          # Attention-based weighted voting
          # Calculate stress score (0-100)
          # Detect contradictions (hidden stress)
          pass
      
      def calculate_stress_score(self, face_emotion, text_emotion, 
                                 face_conf, text_conf, voice_arousal=None):
          # Stress = arousal (from face) + negativity (from text)
          # Score: 0-100
          pass
  ```
- [ ] Create `/api/emotion/fuse` endpoint
- [ ] Implement stress score calculation + storage
- [ ] Create dashboard backend (aggregated stats)

**Frontend Tasks:**
- [ ] Create EmotionDisplay component (shows final fused emotion)
- [ ] Implement stress gauge (circular, 0-100)
- [ ] Create basic Dashboard page (stress history, last 7 sessions)
- [ ] Add real-time emotion updates to WebSocket

**Testing:**
- [ ] Test fusion logic (different combinations)
- [ ] Test stress score edge cases
- [ ] Test dashboard data aggregation
- [ ] End-to-end: video + text â†’ fused emotion â†’ stress score

**Deliverables:**
- Face + text fusion working
- Stress score displayed in real-time
- Dashboard showing historical data
- MVP complete: can have a conversation, see emotions detected

---

## PHASE 2: Voice Emotion (Weeks 5-6)

### 7.2.1 Week 5: Voice Emotion Detection

**Backend Tasks:**
- [ ] Create `voice_emotion_service.py` (Librosa + PyTorch)
  ```python
  import librosa
  import numpy as np
  import torch
  
  class VoiceEmotionService:
      def __init__(self, model_path):
          self.model = self.load_model(model_path)
      
      def extract_features(self, audio_data, sr=16000):
          # MFCC, pitch, energy, ZCR
          mfcc = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=40)
          pitch = librosa.yin(audio_data, fmin=80, fmax=400, sr=sr)
          return {mfcc, pitch, energy, zcr}
      
      def classify_emotion(self, audio_data):
          features = self.extract_features(audio_data)
          emotion = self.model.predict(features)
          return emotion
  ```
- [ ] Set up pre-trained voice emotion model (if available)
  - Option 1: Use HuBERT + fine-tune on IEMOCAP
  - Option 2: Pre-trained SER model from GitHub
- [ ] Create `/api/emotion/analyze-voice` endpoint
- [ ] Implement audio streaming from frontend
- [ ] Create WebSocket audio event handler

**Frontend Tasks:**
- [ ] Implement audio stream capture (Web Audio API)
  ```javascript
  const mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  const audioContext = new AudioContext();
  const source = audioContext.createMediaStreamSource(mediaStream);
  const processor = audioContext.createScriptProcessor(4096, 1, 1);
  
  processor.onaudioprocess = (event) => {
    const audioData = event.inputBuffer.getChannelData(0);
    // Send to backend every 2-5 seconds
  };
  ```
- [ ] Add audio visualization (waveform display)
- [ ] Implement 2-5 second audio buffering + sending

**Testing:**
- [ ] Test voice emotion on IEMOCAP samples
- [ ] Test audio streaming latency
- [ ] Test end-to-end: speak â†’ detect emotion

**Deliverables:**
- Voice emotion detection functional
- Audio streaming working
- 3-modality fusion (face + voice + text) working

---

### 7.2.2 Week 6: Advanced Fusion + Testing

**Backend Tasks:**
- [ ] Refine fusion service to use attention mechanism (optional)
- [ ] Implement hidden stress detection (contradiction flagging)
- [ ] Optimize inference (batch processing, model caching)
- [ ] Comprehensive testing on IEMOCAP dataset

**Frontend Tasks:**
- [ ] Enhance stress gauge to show modality breakdown
- [ ] Add emotion source indication (face: 80%, voice: 20%, text: ...)
- [ ] Real-time emotion update visualization

**Testing & Validation:**
- [ ] Accuracy testing on IEMOCAP (target: 88%+ for face+voice)
- [ ] Full multimodal accuracy (target: 92%+)
- [ ] Load testing (concurrent users, message rate)
- [ ] Integration tests covering full workflow

**Deliverables:**
- Full 3-modality system working
- Accuracy benchmarks documented
- Performance optimized

---

## PHASE 3: Advanced Features & Production (Weeks 7-12)

### 7.3.1 Week 7-8: Burnout Prediction + Multi-Session Tracking

**Backend Tasks:**
- [ ] Implement multi-session trend analysis
- [ ] Create burnout risk calculation algorithm
  ```python
  def calculate_burnout_risk(sessions_history):
      # Multi-dimensional:
      # 1. Stress trend (increasing = bad)
      # 2. Mood average (negative = bad)
      # 3. Emotion variance (high = bad)
      # 4. Session frequency (too many = bad)
      # Risk: LOW (<40), MEDIUM (40-70), HIGH (>70)
      pass
  ```
- [ ] Implement session aggregation (daily stats)
- [ ] Create alerts for escalating stress/burnout

**Frontend Tasks:**
- [ ] Create burnout risk card (dashboard)
- [ ] Implement trend visualization (line chart, stress over time)
- [ ] Add alerts/notifications for burnout risk

**Deliverables:**
- Burnout risk prediction working
- Multi-session tracking + trends
- Alerts implemented

---

### 7.3.2 Week 9-10: Dashboard + Analytics

**Backend Tasks:**
- [ ] Create `/api/dashboard/*` endpoints (all analytics)
- [ ] Implement data aggregation (daily/weekly summaries)
- [ ] Add export functionality (CSV/PDF)

**Frontend Tasks:**
- [ ] Build full Dashboard page
  - Stress trend chart
  - Emotion distribution pie chart
  - Burnout risk indicator
  - Recent sessions list
  - Recommendations
- [ ] Add filters (date range, emotion type)
- [ ] Implement responsive design

**OR Streamlit Alternative:**
```python
import streamlit as st
import plotly.express as px

st.set_page_config(page_title="RIVION Dashboard", layout="wide")

user_data = fetch_user_data(user_id)
stress_history = user_data['stress_timeline']
emotions = user_data['emotions']

st.metric("Current Stress", stress_history[-1], delta=...)
st.line_chart(stress_history)
st.plotly_chart(px.pie(values=emotions, names=emotions.keys()))
```

**Deliverables:**
- Full analytics dashboard
- Export functionality
- Professional-grade visualizations

---

### 7.3.3 Week 11-12: Deployment + Documentation

**DevOps:**
- [ ] Set up production PostgreSQL (AWS RDS or GCP Cloud SQL)
- [ ] Create production Docker setup
- [ ] Configure CI/CD pipeline (auto-deploy on push)
- [ ] Set up monitoring (Sentry, CloudWatch, Datadog)
- [ ] Configure backups + disaster recovery

**Deployment Options:**
- [ ] **AWS** (EC2 + RDS + ALB)
- [ ] **GCP** (Cloud Run + Cloud SQL)
- [ ] **Heroku** (easiest for demo)

**Documentation:**
- [ ] API documentation (OpenAPI/Swagger)
- [ ] Architecture documentation
- [ ] Deployment guide
- [ ] User guide + privacy policy
- [ ] Troubleshooting guide

**Final Testing:**
- [ ] End-to-end testing (all features)
- [ ] Load testing (100+ concurrent users)
- [ ] Security testing (OWASP top 10)
- [ ] Penetration testing

**Deliverables:**
- Deployed system (live URL)
- Full documentation
- Ready for MCA evaluation

---

# 8. DEVELOPMENT ENVIRONMENT SETUP

## 8.1 Local Development Setup (Complete)

### Prerequisites
```bash
# System requirements
â”œâ”€ OS: Ubuntu 20.04+, macOS 12+, or Windows 11 (with WSL2)
â”œâ”€ RAM: 16GB minimum (32GB recommended for ML inference)
â”œâ”€ GPU: Optional but recommended (NVIDIA RTX 3060 or better)
â”œâ”€ Disk: 50GB SSD (for models + databases)
â””â”€ Internet: 50+ Mbps

# Install System Dependencies
## Ubuntu/Debian
sudo apt update
sudo apt install -y python3.11 python3.11-venv python3.11-dev \
                     nodejs npm git postgresql postgresql-contrib \
                     ffmpeg libsndfile1 libportaudio2

## macOS (using Homebrew)
brew install python@3.11 node@18 postgresql ffmpeg portaudio
brew services start postgresql

## Windows (using Chocolatey, in PowerShell as Admin)
choco install python nodejs postgresql ffmpeg vcredist140
```

### Step 1: Clone Repository
```bash
git clone https://github.com/yourusername/RIVION.git
cd RIVION
```

### Step 2: Backend Setup
```bash
cd backend

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt  # for testing/dev tools

# Create .env file
cp .env.example .env
# Edit .env with your settings:
# DATABASE_URL=postgresql://user:password@localhost:5432/rivion_db
# OPENAI_API_KEY=sk-...
# JWT_SECRET=your-secret-key

# Initialize database
python -m alembic upgrade head  # Run migrations

# Or if first time setup
python -c "from app.db.init_db import init_db; init_db()"
```

### Step 3: Frontend Setup
```bash
cd ../frontend

# Install dependencies
npm install

# Create .env file
cp .env.example .env
# Edit .env:
# VITE_API_URL=http://localhost:8000
# VITE_WS_URL=ws://localhost:8000

# Development server
npm run dev  # Runs on http://localhost:5173
```

### Step 4: Docker Setup
```bash
cd ..

# Create docker-compose environment
cp docker-compose.yml docker-compose.override.yml

# Start all services
docker-compose up -d

# Check logs
docker-compose logs -f backend
docker-compose logs -f frontend
docker-compose logs -f db

# Stop services
docker-compose down
```

---

## 8.2 Database Setup

```bash
# Connect to PostgreSQL
psql -U postgres

# Create database and user
CREATE DATABASE rivion_db;
CREATE USER rivion_user WITH PASSWORD 'secure_password';
GRANT ALL PRIVILEGES ON DATABASE rivion_db TO rivion_user;

# Exit psql
\q

# Run migrations
cd backend
alembic revision --autogenerate -m "Initial migration"
alembic upgrade head

# Verify tables
psql -U rivion_user -d rivion_db -c "\dt"
```

---

## 8.3 Model Downloads

```bash
# Create models directory
mkdir -p backend/app/ml_models/{face_models,voice_models,text_models}

# Download DeepFace models (automatic on first use)
python -c "from deepface import DeepFace; DeepFace.build_model('Emotion')"

# Download MediaPipe face detection (automatic)
python -c "import mediapipe as mp; mp.solutions.face_detection"

# Download BERT model (automatic, first inference slower)
python -c "from transformers import pipeline; pipeline('text-classification', model='j-hartmann/emotion-english-distilroberta-base')"

# Download spaCy model
python -m spacy download en_core_web_sm

# Voice emotion model (if not using pre-trained)
# Download from: https://github.com/audeering/w2v2-how-to (or similar)
# Place in: backend/app/ml_models/voice_models/
```

---

## 8.4 IDE Setup

### VS Code Configuration (.vscode/settings.json)
```json
{
  "python.defaultInterpreterPath": "${workspaceFolder}/backend/venv/bin/python",
  "python.linting.enabled": true,
  "python.linting.pylintEnabled": true,
  "python.linting.mypyEnabled": true,
  "python.formatting.provider": "black",
  "[python]": {
    "editor.formatOnSave": true,
    "editor.codeActionsOnSave": {
      "source.organizeImports": true
    }
  },
  "[typescript]": {
    "editor.formatOnSave": true
  },
  "editor.defaultFormatter": "esbenp.prettier-vscode"
}
```

### VS Code Extensions
```
# Install these extensions:
- Python (ms-python.python)
- Pylance (ms-python.vscode-pylance)
- ESLint (dbaeumer.vscode-eslint)
- Prettier (esbenp.prettier-vscode)
- Thunder Client (rangav.vscode-thunder-client) [API testing]
- SQLTools (mtxr.sqltools)
- PostgreSQL (ckolkman.vscode-postgres)
```

---

# 9. DEPLOYMENT & DEVOPS

## 9.1 Docker Setup (Complete)

### Dockerfile (Backend)
```dockerfile
# Multi-stage build for optimization
FROM python:3.11-slim as builder

WORKDIR /app

# Install build dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    libsndfile1 \
    libportaudio2 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY backend/requirements.txt .

# Build dependencies in builder stage
RUN pip install --no-cache-dir --user -r requirements.txt

# Final stage
FROM python:3.11-slim

WORKDIR /app

# Install runtime dependencies only
RUN apt-get update && apt-get install -y \
    libpq5 \
    libsndfile1 \
    libportaudio2 \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

# Copy Python dependencies from builder
COPY --from=builder /root/.local /root/.local

# Add to PATH
ENV PATH=/root/.local/bin:$PATH

# Copy application code
COPY backend /app

# Create non-root user
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/api/health || exit 1

# Run application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Dockerfile (Frontend)
```dockerfile
# Build stage
FROM node:18-alpine as builder

WORKDIR /app

COPY frontend/package*.json ./
RUN npm ci

COPY frontend .
RUN npm run build

# Production stage
FROM node:18-alpine

WORKDIR /app

# Install serve to run SPA
RUN npm install -g serve

COPY --from=builder /app/dist ./dist

EXPOSE 3000

CMD ["serve", "-s", "dist", "-l", "3000"]
```

### docker-compose.yml (Development)
```yaml
version: '3.8'

services:
  db:
    image: postgres:15-alpine
    container_name: rivion_db
    environment:
      POSTGRES_DB: rivion_db
      POSTGRES_USER: rivion_user
      POSTGRES_PASSWORD: rivion_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U rivion_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: rivion_redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build: ./backend
    container_name: rivion_backend
    environment:
      DATABASE_URL: postgresql://rivion_user:rivion_password@db:5432/rivion_db
      REDIS_URL: redis://redis:6379
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      JWT_SECRET: ${JWT_SECRET}
      DEBUG: "true"
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app  # Hot reload in development
    command: >
      sh -c "alembic upgrade head &&
             uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"

  frontend:
    build: ./frontend
    container_name: rivion_frontend
    ports:
      - "3000:3000"
    environment:
      VITE_API_URL: http://localhost:8000
      VITE_WS_URL: ws://localhost:8000
    depends_on:
      - backend
    volumes:
      - ./frontend:/app  # Hot reload
      - /app/node_modules

volumes:
  postgres_data:
```

---

## 9.2 Deployment to AWS

### Step 1: Prepare
```bash
# Build production images
docker-compose build

# Push to ECR (Amazon Container Registry)
aws ecr get-login-password --region us-east-1 | docker login \
  --username AWS --password-stdin 123456789.dkr.ecr.us-east-1.amazonaws.com

docker tag rivion_backend:latest \
  123456789.dkr.ecr.us-east-1.amazonaws.com/rivion-backend:latest
docker push 123456789.dkr.ecr.us-east-1.amazonaws.com/rivion-backend:latest

# Repeat for frontend
```

### Step 2: Infrastructure as Code (Terraform)

```hcl
# main.tf

provider "aws" {
  region = "us-east-1"
}

# VPC
resource "aws_vpc" "rivion" {
  cidr_block = "10.0.0.0/16"
  tags = { Name = "rivion-vpc" }
}

# RDS Database
resource "aws_db_instance" "rivion_db" {
  identifier       = "rivion-db"
  engine           = "postgres"
  engine_version   = "15.1"
  instance_class   = "db.t3.micro"
  allocated_storage = 20
  db_name          = "rivion_db"
  username         = "rivion_user"
  password         = random_password.db_password.result
  publicly_accessible = false
  skip_final_snapshot = true  # For development only
}

# EC2 Instance (Backend)
resource "aws_instance" "backend" {
  ami           = data.aws_ami.ubuntu.id
  instance_type = "t3.medium"
  
  user_data = base64encode(templatefile("${path.module}/user_data.sh", {
    db_host = aws_db_instance.rivion_db.endpoint
    db_user = aws_db_instance.rivion_db.master_username
    db_pass = random_password.db_password.result
  }))
  
  tags = { Name = "rivion-backend" }
}

# Application Load Balancer
resource "aws_lb" "rivion" {
  name               = "rivion-alb"
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb.id]
  subnets            = aws_subnet.public[*].id
}

# Output public IP
output "backend_url" {
  value = aws_lb.rivion.dns_name
}
```

### Step 3: Deploy
```bash
# Initialize Terraform
terraform init

# Plan deployment
terraform plan

# Apply
terraform apply

# Output deployed URL
terraform output backend_url
```

---

## 9.3 CI/CD Pipeline (GitHub Actions)

### .github/workflows/deploy.yml
```yaml
name: Deploy to AWS

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  AWS_REGION: us-east-1
  ECR_REGISTRY: 123456789.dkr.ecr.us-east-1.amazonaws.com

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r backend/requirements-dev.txt
      
      - name: Run tests
        run: |
          pytest backend/tests -v --cov
      
      - name: Run linting
        run: |
          black --check backend/
          pylint backend/app

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
      
      - name: Build, tag, and push backend image
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/rivion-backend:$IMAGE_TAG backend/
          docker push $ECR_REGISTRY/rivion-backend:$IMAGE_TAG

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Deploy to AWS
        run: |
          terraform init
          terraform plan -var="image_tag=${{ github.sha }}"
          terraform apply -auto-approve
```

---

# 10. TESTING STRATEGY

## 10.1 Unit Tests (Backend)

```python
# tests/unit/test_face_emotion_service.py
import pytest
from app.services.face_emotion_service import FaceEmotionService

@pytest.fixture
def face_service():
    return FaceEmotionService()

def test_detect_emotion_happy(face_service):
    # Use pre-recorded happy face frame
    frame = load_test_frame("happy.jpg")
    emotion = face_service.detect_emotion(frame)
    
    assert emotion["emotion"] == "happy"
    assert emotion["confidence"] > 0.7

def test_detect_emotion_no_face(face_service):
    # Blank frame
    frame = np.zeros((640, 480, 3))
    emotion = face_service.detect_emotion(frame)
    
    assert emotion["emotion"] == "unknown"
    assert emotion["confidence"] == 0.0
```

## 10.2 Integration Tests

```python
# tests/integration/test_chat_flow.py
@pytest.mark.asyncio
async def test_full_chat_flow(client, user_token):
    # 1. Start session
    response = client.post("/api/chat/session/start", 
                          headers={"Authorization": f"Bearer {user_token}"})
    session_id = response.json()["session_id"]
    
    # 2. Send message
    response = client.post("/api/chat/message",
                          json={"session_id": session_id, "content": "I'm stressed"},
                          headers={"Authorization": f"Bearer {user_token}"})
    assert response.status_code == 201
    assert "ai_response" in response.json()
    
    # 3. Verify emotion was detected
    response = client.get(f"/api/emotion/history/{session_id}",
                         headers={"Authorization": f"Bearer {user_token}"})
    emotions = response.json()["emotions"]
    assert len(emotions) > 0
    assert emotions[-1]["text_emotion"] is not None
```

## 10.3 E2E Tests (Frontend)

```javascript
// cypress/e2e/chat.spec.js
describe('Chat Flow', () => {
  beforeEach(() => {
    cy.visit('http://localhost:3000');
    cy.login('test@example.com', 'password123');
  });

  it('should send message and receive response', () => {
    cy.get('[data-testid=chat-input]').type('I feel anxious');
    cy.get('[data-testid=send-button]').click();
    
    cy.contains('I feel anxious').should('be.visible');
    cy.get('[data-testid=ai-message]').should('be.visible');
  });

  it('should display emotion detection', () => {
    cy.get('[data-testid=emotion-display]').should('contain', 'emotion');
    cy.get('[data-testid=stress-gauge]').should('be.visible');
  });
});
```

---

# 11. BEST PRACTICES & STANDARDS

## 11.1 Code Organization Principles

```
â”œâ”€ Single Responsibility: Each module does ONE thing
â”œâ”€ DRY (Don't Repeat Yourself): Reusable functions/components
â”œâ”€ SOLID Principles: For backend services
â”œâ”€ Dependency Injection: Loose coupling
â”œâ”€ Asyncio: Always async I/O operations
â””â”€ Type Hints: Full type annotations (mypy)
```

## 11.2 API Design Standards

```
â”œâ”€ RESTful endpoints (nouns, not verbs)
â”œâ”€ Consistent response format:
â”‚  {
â”‚    "status": "success" | "error",
â”‚    "data": {...},
â”‚    "error": {...},
â”‚    "timestamp": "2025-12-05T..."
â”‚  }
â”œâ”€ Proper HTTP status codes (201, 400, 401, 404, 500)
â”œâ”€ Pagination (offset + limit) for lists
â”œâ”€ Rate limiting (429 if exceeded)
â””â”€ API versioning (/api/v1/*, /api/v2/*)
```

## 11.3 Security Practices

```
â”œâ”€ Never log sensitive data (passwords, API keys, tokens)
â”œâ”€ Use environment variables for secrets
â”œâ”€ Validate all user inputs
â”œâ”€ Use parameterized queries (SQL injection prevention)
â”œâ”€ CORS: Whitelist specific origins
â”œâ”€ HTTPS in production (not HTTP)
â”œâ”€ JWT expiration: 1 hour (refresh token: 7 days)
â”œâ”€ Password hashing: bcrypt (not plain text)
â”œâ”€ Rate limiting: 100 requests/minute per IP
â””â”€ OWASP Top 10 compliance
```

## 11.4 Performance Optimization

```
â”œâ”€ Model caching (load once, reuse)
â”œâ”€ Database indexing (on frequently queried fields)
â”œâ”€ Connection pooling (reuse DB connections)
â”œâ”€ Redis caching (session data, aggregated stats)
â”œâ”€ Async all I/O (never block with sleep())
â”œâ”€ Batch processing (group similar requests)
â”œâ”€ CDN for static assets (React bundle, CSS)
â”œâ”€ Database query optimization (explain analyze)
â””â”€ Load testing (simulate 100+ concurrent users)
```

---

# 12. TIMELINE & RESOURCE ALLOCATION

## 12.1 Weekly Breakdown (12 Weeks Total)

| Week | Phase | Backend (hrs) | Frontend (hrs) | DevOps (hrs) | Total |
|------|-------|--------------|---|---|---|
| 1 | Setup | 15 | 15 | 10 | 40 |
| 2 | Face Emotion | 20 | 20 | 5 | 45 |
| 3 | Text + Chat | 25 | 20 | 5 | 50 |
| 4 | Fusion | 15 | 15 | 5 | 35 |
| 5 | Voice (Pt1) | 25 | 15 | 5 | 45 |
| 6 | Voice (Pt2) | 20 | 10 | 5 | 35 |
| 7 | Burnout | 20 | 15 | 5 | 40 |
| 8 | Advanced Features | 15 | 20 | 5 | 40 |
| 9 | Dashboard | 10 | 30 | 5 | 45 |
| 10 | Testing | 20 | 15 | 5 | 40 |
| 11 | Deployment | 15 | 10 | 25 | 50 |
| 12 | Documentation | 10 | 10 | 5 | 25 |
| **TOTAL** | | **225 hrs** | **195 hrs** | **85 hrs** | **505 hrs** |

**Average: 20.2 hours/week (part-time MCA project)**

---

## 12.2 Resource Requirements

### Hardware
- Laptop: 16GB RAM, SSD (your own)
- GPU (optional): NVIDIA RTX 3060+ (rent from Paperspace/Lambda Labs: $10-30/month)

### Software (Free/Open Source)
- Python, Node.js, PostgreSQL, Redis (all free)
- FastAPI, React, PyTorch, HuggingFace (all free)

### Paid Services (Recommended Budget)
| Service | Purpose | Cost/Month |
|---------|---------|-----------|
| **OpenAI API** | LLM responses | $20-50 |
| **AWS/GCP** | Cloud hosting | $50-150 |
| **Sentry** | Error tracking | $0 (free tier) |
| **GitHub Pro** | Private repos | $4 |
| **Domain** | Custom domain | $10-15 |
| **SSL Certificate** | HTTPS | $0 (free: Let's Encrypt) |
| **TOTAL** | | ~$100-200/month |

---

# 13. TROUBLESHOOTING GUIDE

## 13.1 Common Backend Issues

### Issue 1: CUDA Out of Memory (GPU)
```python
# Error: torch.cuda.OutOfMemoryError

# Solutions:
1. Reduce batch size in inference
2. Use smaller models (DistilBERT instead of BERT)
3. Offload to CPU temporarily
4. Restart GPU memory with: torch.cuda.empty_cache()
```

### Issue 2: Database Connection Timeouts
```python
# Error: psycopg2.OperationalError: could not connect

# Solutions:
1. Check PostgreSQL is running: `systemctl status postgresql`
2. Verify DATABASE_URL in .env
3. Reset connection pool: `db.dispose()` in SQLAlchemy
4. Increase connection timeout: `pool_pre_ping=True`
```

### Issue 3: WebSocket Connection Fails
```
# Error: WebSocket connection failed

# Solutions:
1. Check CORS headers match frontend origin
2. Verify WebSocket URL in frontend .env
3. Ensure backend listening on correct port
4. Check firewall/network rules allow WebSocket
```

---

## 13.2 Common Frontend Issues

### Issue 1: getUserMedia Permission Denied
```javascript
// Error: NotAllowedError: Permission denied

// Solutions:
1. User must grant camera/mic permission (browser prompt)
2. HTTPS required in production (not localhost:3000)
3. Clear browser permissions: Settings â†’ Privacy â†’ Clear site data
```

### Issue 2: API Calls Return 401 Unauthorized
```javascript
// Solution:
const token = localStorage.getItem('auth_token');
if (!token) {
  // Not logged in
  redirectToLogin();
}

// Include token in headers:
fetch('/api/endpoint', {
  headers: {
    'Authorization': `Bearer ${token}`
  }
});
```

---

# APPENDIX: CODE TEMPLATES

## A1. FastAPI Main Entry Point (main.py)

```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZIPMiddleware
from contextlib import asynccontextmanager

from app.config import settings
from app.routers import auth, chat, emotion, dashboard
from app.middleware import ErrorHandlingMiddleware
from app.db.database import engine, Base

# Create tables
Base.metadata.create_all(bind=engine)

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    print("Starting RIVION backend...")
    yield
    # Shutdown
    print("Shutting down...")

app = FastAPI(
    title="RIVION API",
    version="1.0.0",
    lifespan=lifespan
)

# Middleware
app.add_middleware(GZIPMiddleware, minimum_size=1000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(ErrorHandlingMiddleware)

# Routers
app.include_router(auth.router, prefix="/api", tags=["auth"])
app.include_router(chat.router, prefix="/api", tags=["chat"])
app.include_router(emotion.router, prefix="/api", tags=["emotion"])
app.include_router(dashboard.router, prefix="/api", tags=["dashboard"])

@app.get("/api/health")
async def health_check():
    return {"status": "healthy", "version": "1.0.0"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

---

## A2. React Chat Component (ChatPage.tsx)

```typescript
import React, { useEffect, useRef, useState } from 'react';
import { useWebRTC } from '@/hooks/useWebRTC';
import { useEmotion } from '@/hooks/useEmotion';
import { VideoChat } from '@/components/VideoChat/VideoChat';
import { ChatBox } from '@/components/VideoChat/ChatBox';
import { EmotionDisplay } from '@/components/VideoChat/EmotionDisplay';

export const ChatPage: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement>(null);
  const { video, sendMessage } = useWebRTC();
  const { emotion, stressScore, hidden_stress } = useEmotion();

  return (
    <div className="grid grid-cols-2 gap-6 p-6 h-screen">
      {/* Video Section */}
      <div className="col-span-1">
        <VideoChat videoRef={videoRef} emotion={emotion} />
        <EmotionDisplay 
          emotion={emotion}
          stressScore={stressScore}
          hiddenStress={hidden_stress}
        />
      </div>

      {/* Chat Section */}
      <div className="col-span-1">
        <ChatBox onSendMessage={sendMessage} />
      </div>
    </div>
  );
};
```

---

*This completes the comprehensive RIVION implementation report.*

**Total Documentation: ~15,000 words covering all aspects from requirements to deployment.**

**Next Steps:**
1. Customize for your specific needs
2. Adapt timelines based on your team size
3. Start with Phase 1 MVP (face + text)
4. Iterate and improve based on testing
5. Document your progress for MCA evaluation
